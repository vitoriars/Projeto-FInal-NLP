{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto final NLP - Parte III.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_C6VT1femh8",
        "colab_type": "text"
      },
      "source": [
        "# Parte III - Word Vectors\n",
        "\n",
        "E aí, querido leitor. Bem vinde a parte três do meu projeto de NLP. Nessa parte, vamos ver como usar o Word2Vec, que funcionará como os outros modelos aplicados nas outras etapas do projeto mas com uma diferença de que esse captura contextos.\n",
        "Ele faz isso transformando as palavras em vetores e mapeando o contexto em que elas ocorrem com relação a outras palavras. Vamos começar então! \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgFC5Nopf5nt",
        "colab_type": "text"
      },
      "source": [
        "## Pré-processamento\n",
        "\n",
        "Para esta parte do projeto precisaríamos realizar um pré-processamento semelhante ao da primeira parte, porém, por ser uma função que demora muito tempo para rodar acabei optando por guardar o texto já processado em um novo dataframe, por isso vamos apenas ler esse arquivo e partir direto para o Word2Vec.\n",
        "\n",
        "Caso queira relembrar a função usada [clique aqui](https://github.com/vitoriars/Projeto-Final-NLP/blob/master/Projeto_final_NLP_Parte_I.ipynb) para ver a primeira parte do projeto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8kengWrhIPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f23cba0e-3339-42ce-ce71-310f1110ca36"
      },
      "source": [
        "#importando a biblioteca\n",
        "import pandas as pd\n",
        "\n",
        "#lendo o dataframe\n",
        "df = pd.read_csv('df_clean.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one reviewers mention watch oz episode hook ri...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful little production filming technique ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>think wonderful way spend time hot summer week...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically family little boy jake think zombie ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei love time money visually stunnin...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  one reviewers mention watch oz episode hook ri...  positive\n",
              "1  wonderful little production filming technique ...  positive\n",
              "2  think wonderful way spend time hot summer week...  positive\n",
              "3  basically family little boy jake think zombie ...  negative\n",
              "4  petter mattei love time money visually stunnin...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj19djSJlNln",
        "colab_type": "text"
      },
      "source": [
        "Tudo certo. Aqui o texto já está processado, sem tags html e stopwords, com todas as letras minúsculas e lemmatizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7va0RzolgCs",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHEaZrq-CDx8",
        "colab_type": "text"
      },
      "source": [
        "### Preparando o texto\n",
        "\n",
        "Chegamos na parte do modelo. Mas primeiro precisamos preparar o nosso texto, isso porque o Word2Vec só recebe como input uma lista de listas, então precisamos transformá-lo. Vamos lá:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx-YbNhGSivU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "fc921955-1f1a-4880-a8f5-58b60b392b6a"
      },
      "source": [
        "#biblioteca\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkRnGXYR_c-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texto = [word_tokenize(row) for row in df['review']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTqlTqaYC5n4",
        "colab_type": "text"
      },
      "source": [
        "### Detectando bigramas\n",
        "\n",
        "Mais uma coisa antes de partirmos para o modelo: precisamos detectar bigramas no texto, fazemos isso para que o world2vec aprenda a diferenciar bigramas em seus contextos. Para isso, vamos utilizar a biblioteca `gensim`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8MbLDJtPl0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQgljxh7IWxm",
        "colab_type": "text"
      },
      "source": [
        "Agora passamos o texto onde queremos procurar bigramas e definimos que a palavra precisa aparecer pelo menos 30 vezes para ser considerada um bigrama:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUK0IwuPSpPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phrases = Phrases(texto, min_count=2, threshold=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdXN_6ifU5nD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram = Phraser(phrases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfuYPydwIv4g",
        "colab_type": "text"
      },
      "source": [
        "Vamos ver se achamos algum bigrama no nosso texto! Vou colocar para procurar o bigrama Tom Cruise, que por ser um ator famoso deve aparecer várias vezes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1tSBgzo6mdA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e7c2b91d-34cf-46e6-8dfa-4280ac443f07"
      },
      "source": [
        "print(bigram['tom cruise is awesome'.split()]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tom_cruise', 'is', 'awesome']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dzd6uJqJBEu",
        "colab_type": "text"
      },
      "source": [
        "O texto reconheceu Tom Cruise como um bigrama! Sabemos disso porque ele juntou as palavras com um underline (que é como o phrases 'marca' os bigramas em um texto). Vamos então aplicar para que esses bigramas sejam permanentes no nosso texto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEX7yqO6U6Kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " sentences = bigram[texto] #tudo certinho"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TxiXkReN6En",
        "colab_type": "text"
      },
      "source": [
        "### Ajustando o modelo\n",
        "\n",
        "Com nosso texto pronto para o input podemos começar a parte do modelo. Bora lá! Vamos importar as bibliotecas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiAS80ElPGSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ-G1aptSOJ9",
        "colab_type": "text"
      },
      "source": [
        "Vamos ajustar alguns parâmetros ao modelo: \n",
        "* o primeiro é o `size`, que representa a dimensão do espaço vetorial, normalmente um valor de 50 a 300. Aqui valores maiores exigem mais dados de treinamento, mas podem levar a modelos melhores. Como nosso df não é tão grande (50 mil linhas) vamos ajustá-lo para `100`; \n",
        "* Depois vamos ajustar o `min_count` que é a quatidade de vezes que uma palavra precisa aparecer para ser treinada. Palvras que aparecem apenas uma ou duas vezes em um texto de bilhões de palavras provavelmente são insignificantes, então é melhor ignorá-las: aqui vamos colocar `5`, que é o valor padrão para esse parâmetro segundo a documentação;\n",
        "* No parâmetro `window`, que se trata da distância da palavra atual e a que queremos prever vamos colocar 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc1VsiJIPID3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v = Word2Vec(min_count=4, size=80, window=2) #modelo preparado!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJEHVYsNXTrw",
        "colab_type": "text"
      },
      "source": [
        "### Tabela de vocabulário\n",
        "\n",
        "O word2vec pede pela construção de uma tabela de vocabulário, onde ele filtra as palavras importantes e faz algumas contagens. Então vamos construí-la:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86N_hpuGX7-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v.build_vocab(sentences) #tabela feita"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCgRic16a3aA",
        "colab_type": "text"
      },
      "source": [
        "### Treinando o modelo\n",
        "\n",
        "Vamos agora para o treinamento do modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Veu2Fdxxa_f5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a48827b-c153-4748-da69-d170ade5a0e3"
      },
      "source": [
        "w2v.train(sentences, total_examples=w2v.corpus_count, epochs=20, report_delay=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100018577, 109487960)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7FGDo4ziMjY",
        "colab_type": "text"
      },
      "source": [
        "## Analisando o resultado\n",
        "\n",
        "Nosso modelo está pronto! Agora vamos analisar alguns resultados com funções que o word2vec nos proporciona."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuHtsCx0idKI",
        "colab_type": "text"
      },
      "source": [
        "### most_similar\n",
        "\n",
        "Vamos usar essa função para ver quais são algumas palavras similares de acordo com o contexto das reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO2pTZPKkIH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "ddf89de5-682b-475e-9869-b089737d8d26"
      },
      "source": [
        "w2v.wv.most_similar(positive=[\"movie\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('film', 0.8933265209197998),\n",
              " ('flick', 0.6963775753974915),\n",
              " ('movies', 0.692674994468689),\n",
              " ('films', 0.5871027112007141),\n",
              " ('picture', 0.5818313360214233),\n",
              " ('thriller', 0.5563170909881592),\n",
              " ('campfire_tales', 0.5511619448661804),\n",
              " ('flatliners', 0.5501915216445923),\n",
              " ('horror_flick', 0.549239456653595),\n",
              " ('slashers', 0.514405369758606)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJeUD9avkS0Y",
        "colab_type": "text"
      },
      "source": [
        "Aqui podemos ver que a palavra que mais se relaciona com \"movie\" é \"film\", o que faz sentido já que são sinônimos. Em seguida temos várias outras palavras que realmente se relacionam. A palavra mais curiosa é \"really\" que não parece ter *tanta* relação assim com \"movie\" (de um ponto de vista humano, não do modelo). Provavelmente essa palavra pode ter sido usada muitos vezes para aumentar o valor do adjetivo que caracteriza o filme, por exemplo, é muito comum dizermos frases como \"this movie is **really** good\" ou \"**really** bad\", etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVGuRZ8ekQw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "1f7d0f10-37de-4d5e-c3c2-29488cfdb1de"
      },
      "source": [
        "w2v.wv.most_similar(positive=[\"good\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('decent', 0.7700533866882324),\n",
              " ('great', 0.7157161235809326),\n",
              " ('bad', 0.6862451434135437),\n",
              " ('nice', 0.634381890296936),\n",
              " ('cool', 0.613572359085083),\n",
              " ('fairly_decent', 0.6080654859542847),\n",
              " ('excellent', 0.5941331386566162),\n",
              " ('alright', 0.5888383388519287),\n",
              " ('okay', 0.5853169560432434),\n",
              " ('halfway_decent', 0.58482825756073)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdThgdcplVX7",
        "colab_type": "text"
      },
      "source": [
        "Aqui exploramos quais palavras mais se relacionam com o adjetivo \"good\", as mais próximas são \"decent\" e \"great\", o que parece estar certo. Também as outras palavras são todas adjetivos, o que faz muito sentido!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zn8PyIElTyo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "b139c127-39c1-435b-83eb-dba76da1f2c6"
      },
      "source": [
        "w2v.wv.most_similar(positive=[\"tom_cruise\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kevin_costner', 0.635523796081543),\n",
              " ('roger_moore', 0.6126630902290344),\n",
              " ('gosford_park', 0.6042460203170776),\n",
              " ('mr_magoo', 0.5911063551902771),\n",
              " ('enemy_state', 0.5860060453414917),\n",
              " ('total_recall', 0.5779522657394409),\n",
              " ('batman_robin', 0.5756421089172363),\n",
              " ('clark_gable', 0.575323224067688),\n",
              " ('anthony_hopkins', 0.5689816474914551),\n",
              " ('marlon_brando', 0.5679072737693787)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMFdJywWnEEi",
        "colab_type": "text"
      },
      "source": [
        "Podemos ver também que a palavra mais relacionada a Tom Cruise é Kevin Costner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ochcqUxnBMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "06bd61e5-9ac4-47de-8f3e-0ce116674c77"
      },
      "source": [
        "w2v.wv.most_similar(positive=[\"actor\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actress', 0.8151911497116089),\n",
              " ('actors', 0.7201424837112427),\n",
              " ('performer', 0.6442574262619019),\n",
              " ('comedian', 0.6301604509353638),\n",
              " ('dennis_hopper', 0.6170964241027832),\n",
              " ('actors_actresse', 0.5975667238235474),\n",
              " ('kevin_spacey', 0.5833142399787903),\n",
              " ('cast_member', 0.5771658420562744),\n",
              " ('actresses', 0.577154278755188),\n",
              " ('actresse', 0.5747847557067871)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_0PgNGenRt-",
        "colab_type": "text"
      },
      "source": [
        "Semelhanças com a palavra \"actor\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDkPIWoinXxH",
        "colab_type": "text"
      },
      "source": [
        "### similarity\n",
        "\n",
        "Com essa função podemos ver o quão similar são duas palavras, aleatórias ou não:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3EHgLpmnQGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "706a25be-70a4-4eca-a4ff-dc51453101b7"
      },
      "source": [
        "w2v.wv.similarity('movie', 'actor')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31180236"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LILwqxPfqOqf",
        "colab_type": "text"
      },
      "source": [
        "Aqui vemos que as palavras \"movie\" e \"actor\" possuem só 28% de semelhança."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpHvyLBO0mV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6c28d750-79b7-4386-c77e-f2b97aaa12e4"
      },
      "source": [
        "w2v.wv.similarity('good', 'bad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.68624514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUgUhni40p0q",
        "colab_type": "text"
      },
      "source": [
        "A semelhança entre \"good\" e \"bad\" é de apenas 68%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGcDVRJR0tfH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "386cb763-39ca-4543-b470-0c441b0795b5"
      },
      "source": [
        "w2v.wv.similarity('actress', 'actor')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81519115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__iOh1Xo0xt-",
        "colab_type": "text"
      },
      "source": [
        "Entre \"actor\" e \"actress\" é 81%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVPi6bvpshlB",
        "colab_type": "text"
      },
      "source": [
        "### doesnt_match\n",
        "\n",
        "Com essa função podemos escolher várias palavras e fazer com que o modelo acerte a palavra que não tem relação com a lista. Por exemplo, a seguir montei uma lista com a palavra filme e seus genêros e adicionei o nome Tom Cruise, que é um ator. Vamos ver qual palavra o modelo nos retorna como não pertencente à lista?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNrZky5tsr_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "6b147f50-7bd0-46c6-ad80-d7bc7f32979a"
      },
      "source": [
        "w2v.wv.doesnt_match(['movie', 'drama', 'action','comedy','tom_cruise'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tom_cruise'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Ieqbl6XoaR",
        "colab_type": "text"
      },
      "source": [
        "Aqui o modelo retorna que Tom Cruise não pertece à lista. Isso faz muito sentido já que é a palavra que menos se relacionam com as outras!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_or_3u4mtAtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3f4f570f-9f96-43c3-9d5b-10a9ef1466ee"
      },
      "source": [
        "w2v.wv.doesnt_match(['good', 'bad', 'decent', 'movie', 'great'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'movie'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFkdLDWCXyRn",
        "colab_type": "text"
      },
      "source": [
        "Aqui vemos que em uma lista de adjetivos a palavra 'movie' é a que mais se diferencia, portanto, não pertence a lista."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QBE2x7adIZf",
        "colab_type": "text"
      },
      "source": [
        "## Conclusão\n",
        "\n",
        "Essa foi a última parte do Projeto de NLP. Durante todo o projeto aprendi vários assuntos, tanto básicos, como fazer um pré-processamento simples, quanto mais avançados como implementar diferentes modelos ao meu texto. Vi que temos diferentes maneiras de realizarmos tarefas semelhantes e que precisamos ter essa intuição de que tipo de modelo funcionaria para determinada tarefa. Também aprendi que cada modelo e cada tarefa pode exigir um pré-processamento diferente, por isso alguns conceitos básicos com stopwords, .lower, regex, etc, são tão importantes.\n",
        "\n",
        "Obrigada novamente a Julia por ter me auxiliado, principalmente durante essa última parte. Amei ter aprendido tanta coisa desde que entrei no grupo e estou animada para aprender cada vez mais!\n",
        "\n"
      ]
    }
  ]
}